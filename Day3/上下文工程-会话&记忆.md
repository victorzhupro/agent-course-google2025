# 上下文工程：会话与记忆

**作者：Kimberly Milam 和 Antonio Gulli**

**致谢**

内容贡献者：

- Kaitlin Ardiff
- Shangjie Chen
- Yanfei Chen
- Derek Egan
- Hangfei Lin
- Ivan Nardini
- Anant Nawalgaria
- Kanchana Patlolla
- Huang Xia
- Jun Yan
- Bo Yang
- Michael Zimmermann

策展和编辑：

- Anant Nawalgaria
- Kanchana Patlolla

设计师：

- Michael Lanning

---

# 目录

1. [引言](#1-引言)
2. [上下文工程](#2-上下文工程)
3. [会话](#3-会话)
   - 3.1 [跨框架和模型的差异](#31-跨框架和模型的差异)
   - 3.2 [多智能体系统中的会话](#32-多智能体系统中的会话)
   - 3.3 [跨多个智能体框架的互操作性](#33-跨多个智能体框架的互操作性)
   - 3.4 [会话的生产环境考量](#34-会话的生产环境考量)
   - 3.5 [管理长上下文对话：权衡与优化](#35-管理长上下文对话权衡与优化)
4. [记忆](#4-记忆)
   - 4.1 [记忆类型](#41-记忆类型)
   - 4.2 [信息类型](#42-信息类型)
   - 4.3 [组织模式](#43-组织模式)
   - 4.4 [存储架构](#44-存储架构)
   - 4.5 [创建机制](#45-创建机制)
   - 4.6 [记忆范围](#46-记忆范围)
   - 4.7 [多模态记忆](#47-多模态记忆)
   - 4.8 [记忆生成：提取与巩固](#48-记忆生成提取与巩固)
   - 4.9 [记忆溯源](#49-记忆溯源)
   - 4.10 [触发记忆生成](#410-触发记忆生成)
   - 4.11 [记忆作为工具](#411-记忆作为工具)
   - 4.12 [后台与阻塞操作](#412-后台与阻塞操作)
   - 4.13 [记忆检索](#413-记忆检索)
   - 4.14 [推理中的记忆](#414-推理中的记忆)
   - 4.15 [程序性记忆](#415-程序性记忆)
5. [测试与评估](#5-测试与评估)
6. [记忆的生产环境考量](#6-记忆的生产环境考量)
7. [隐私与安全风险](#7-隐私与安全风险)
8. [结论](#8-结论)
9. [尾注](#9-尾注)

---

## 1. 引言

有状态和个人化的AI始于上下文工程。

本白皮书探讨了会话（Sessions）和记忆（Memory）在构建有状态、智能的LLM智能体中的关键作用，旨在赋能开发者创建更强大、个性化且持久的AI体验。为了使大型语言模型（LLMs）能够记住信息、学习并个性化交互，开发者必须在其上下文窗口内动态组装和管理信息——这一过程被称为上下文工程。

以下核心概念在本白皮书中进行了总结：

- **上下文工程**：在LLM的上下文窗口内动态组装和管理信息，以启用有状态、智能智能体的过程。
- **会话**：与智能体完整对话的容器，保存对话的时间顺序历史记录和智能体的工作记忆。
- **记忆**：长期持久化的机制，跨多个会话捕获和巩固关键信息，为LLM智能体提供连续且个性化的体验。

---

## 2. 上下文工程

LLM本质上是无状态的。除了训练数据之外，它们的推理和感知仅限于单个API调用的"上下文窗口"内提供的信息。这带来了一个根本性的问题，因为AI智能体必须配备操作指令，明确可以采取哪些行动、需要推理的证据和事实数据，以及定义当前任务的即时对话信息。

为了构建能够记住、学习和个性化交互的有状态智能智能体，开发者必须在每次对话轮次中构建这个上下文。这种为LLM动态组装和管理信息的过程被称为**上下文工程**。

上下文工程代表了从传统提示工程的演进。提示工程专注于制作最优的、通常是静态的系统指令。相反，上下文工程处理整个有效载荷，基于用户、对话历史和外部数据动态构建有状态的提示。它涉及战略性地选择、总结和注入不同类型的信息，以最大化相关性，同时最小化噪音。

外部系统（如RAG数据库、会话存储和记忆管理器）管理大部分上下文。智能体框架必须协调这些系统，检索并将上下文组装到最终的提示中。

将上下文工程视为智能体的"mise en place"（烹饪前的准备工作）——这是厨师在烹饪前收集和准备所有食材的关键步骤。如果你只给厨师食谱（提示），他们可能会用现有的随机食材做出还不错的饭菜。然而，如果你首先确保他们拥有所有正确、高质量的食材、专业工具，并对呈现风格有清晰的理解，他们就能可靠地做出优秀、定制的结果。

上下文工程的目标是确保模型拥有完成其任务所需的、不多不少的最相关信息。

上下文工程管理着一个复杂有效载荷的组装，可以包含多种组件：

**指导推理的上下文**定义了智能体的基本推理模式和可用操作，决定了其行为：

- **系统指令**：定义智能体角色、能力和约束的高级指令。
- **工具定义**：智能体可用于与外部世界交互的API或函数的架构。
- **少样本示例**：通过上下文学习指导模型推理过程的精选示例。

**证据和事实数据**是智能体推理的实质性数据，包括特定任务的现有知识和动态检索信息；它作为智能体响应的"证据"：

- **长期记忆**：跨多个会话收集的关于用户或主题的持久化知识。
- **外部知识**：从数据库或文档中检索的信息，通常使用检索增强生成（RAG）。
- **工具输出**：工具返回的数据或结果。
- **子智能体输出**：被委派特定子任务的专门智能体返回的结论或结果。
- **制品**：与用户或会话相关的非文本数据（例如，文件、图像）。

**即时对话信息**将智能体置于当前交互中，定义即时任务：

- **对话历史**：当前交互的逐轮记录。
- **状态/草稿本**：智能体用于其即时推理过程的临时、进行中信息或计算。
- **用户提示**：需要处理的即时查询。

上下文的动态构建至关重要。例如，记忆不是静态的；随着用户与智能体的交互或摄取新数据，必须选择性地检索和更新它们。此外，有效的推理通常依赖于上下文学习（智能体从提示中的演示学习如何执行任务的过程）。当智能体使用与当前任务相关的少样本示例而不是依赖硬编码示例时，上下文学习会更有效。类似地，外部知识是基于用户的即时查询由RAG工具检索的。

构建上下文感知智能体的最关键挑战之一是管理不断增长的对话历史。理论上，具有大上下文窗口的模型可以处理大量的记录；但实际上，随着上下文的增长，成本和延迟都会增加。

此外，模型可能会遭受"上下文腐烂"（context rot）现象——随着上下文的增长，它们关注关键信息的能力会减弱。上下文工程通过采用动态变异历史记录的策略直接解决这一问题——例如摘要、选择性修剪或其他压缩技术——以保留重要信息，同时管理总token数量，最终实现更稳健和个性化的AI体验。

这一实践在智能体操作循环中的每一轮对话中表现为一个连续循环：

**图1. 智能体上下文管理流程**

1. **获取上下文**：智能体首先检索上下文——如用户记忆、RAG文档和最近的对话事件。对于动态上下文检索，智能体将使用用户查询和其他元数据来识别要检索哪些信息。
2. **准备上下文**：智能体框架动态构建LLM调用的完整提示。虽然单个API调用可能是异步的，但准备上下文是一个阻塞的"热路径"过程。智能体必须等待上下文准备就绪才能继续。
3. **调用LLM和工具**：智能体迭代调用LLM和任何必要的工具，直到为用户生成最终响应。工具和模型输出被附加到上下文中。
4. **上传上下文**：轮次中收集的新信息被上传到持久化存储。这通常是一个"后台"过程，允许智能体完成执行，而记忆巩固或其他后处理异步发生。

在此生命周期的核心是两个基本组件：**会话**和**记忆**。会话管理单次对话的逐轮状态。相比之下，记忆提供了长期持久化的机制，跨多个会话捕获和巩固关键信息。

你可以将会话视为用于特定项目的工作台或桌子。工作时，它上面覆盖着所有必要的工具、笔记和参考资料。所有东西都可以立即访问，但也是临时的，特定于当前任务。项目完成后，你不会把整个凌乱的桌子塞进储物间。相反，你开始创建记忆的过程，这就像一个有组织的文件柜。你审查桌子上的材料，丢弃草稿和冗余笔记，只将最关键、最终的文件归档到标记的文件夹中。这确保了文件柜仍然是一个干净、可靠、高效的未来项目事实来源，而不会被工作台的临时混乱所污染。这个比喻直接反映了一个有效智能体的运作方式：会话作为单次对话的临时工作台，而智能体的记忆是精心组织的文件柜，使其能够在未来交互中回忆起关键信息。

基于上下文工程的高级概述，我们现在可以探索两个核心组件：会话和记忆，从会话开始。

---

## 3. 会话

上下文工程的一个基础元素是会话，它封装了单次连续对话的即时对话历史和工作记忆。每个会话是一个独立的记录，与特定用户关联。会话允许智能体在单次对话范围内保持上下文并提供连贯的响应。一个用户可以有多个会话，但每个会话都作为特定交互的独立、断开的日志。每个会话包含两个关键组件：时间顺序历史（事件）和智能体的工作记忆（状态）。

**事件**是对话的构建块。常见的事件类型包括：用户输入（来自用户的消息（文本、音频、图像等））、智能体响应（智能体对用户的回复）、工具调用（智能体使用外部工具或API的决定），或工具输出（工具调用返回的数据，智能体用它来继续推理）。

除了聊天历史，会话通常还包括**状态**——一个结构化的"工作记忆"或草稿本。这保存与当前对话相关的临时、结构化数据，比如购物车中的物品。

随着对话的进行，智能体将向会话附加额外的事件。此外，它可能会根据智能体中的逻辑改变状态。

事件的结构类似于传递给Gemini API的Content对象列表，其中每个具有角色和parts的项目代表对话中的一轮——或一个事件。

```python
contents = [
  {
    "role": "user",
    "parts": [{"text": "What is the capital of France?"}]
  }, {
    "role": "model",
    "parts": [{"text": "The capital of France is Paris."}]
  }
]

response = client.models.generate_content(
  model="gemini-2.5-flash",
  contents=contents
)
```

**代码片段1：Gemini多轮调用示例**

生产智能体的执行环境通常是无状态的，意味着请求完成后不会保留任何信息。因此，必须将对话历史保存到持久化存储，以保持连续的用户体验。虽然内存存储适合开发，但生产应用应利用强大的数据库来可靠地存储和管理会话。例如，您可以将对话历史存储在托管解决方案如Agent Engine Sessions中。

### 3.1 跨框架和模型的差异

虽然核心思想相似，但不同的智能体框架以不同的方式实现会话、事件和状态。智能体框架负责维护LLM的对话历史和状态，使用此上下文构建LLM请求，以及解析和存储LLM响应。

智能体框架充当您的代码与LLM之间的通用转换器。当您（开发者）使用框架一致的内部数据结构处理每个对话轮次时，框架处理将这些结构转换为LLM所需精确格式的关键任务。这种抽象很强大，因为它将您的智能体逻辑与您使用的特定LLM解耦，防止供应商锁定。

**图2. 智能体上下文管理流程**

最终，目标是生成LLM可以理解的"请求"。对于Google的Gemini模型，这是一个List[Content]。每个Content对象是一个简单的类字典结构，包含两个键：定义谁在说话的角色（"user"或"model"）和定义消息实际内容的parts（文本、图像、工具调用等）。

框架自动处理将其内部对象（例如ADK Event）映射到Content对象中的相应角色和parts，然后再进行API调用。

本质上，框架为开发者提供稳定的内部API，同时在幕后管理不同LLM的复杂且多样的外部API。

**ADK**使用显式的Session对象，包含Event对象列表和单独的state对象。Session就像一个文件柜，一个文件夹用于对话历史（事件），另一个用于工作记忆（状态）。

**LangGraph**没有正式的"会话"对象。相反，状态就是会话。这个包罗万象的状态对象保存对话历史（作为Message对象列表）和所有其他工作数据。与传统会话的仅附加日志不同，LangGraph的状态是可变的。它可以转换，像历史压缩这样的策略可以改变记录。这对于管理长对话和token限制很有用。

### 3.2 多智能体系统中的会话

在多智能体系统中，多个智能体协作。每个智能体专注于较小的、专门的任务。为了使这些智能体有效协作，它们必须共享信息。如下图所示，系统的架构定义了它们用于共享信息的通信模式。该架构的一个核心组件是系统如何处理会话历史——所有交互的持久化日志。

**图3. 不同的多智能体架构模式**

在探索管理此历史的架构模式之前，必须将其与发送到LLM的上下文区分开。将会话历史视为整个对话的永久、完整记录。另一方面，上下文是发送到LLM的、经过精心制作的信息有效载荷。智能体可能会通过仅选择历史的相关摘录或添加特殊格式（如引导性前言）来构建此上下文，以引导模型的响应。本节重点介绍在智能体之间传递哪些信息，而不一定是发送到LLM的上下文。

智能体框架使用两种主要方法之一来处理多智能体系统的会话历史：所有智能体贡献于单个日志的**共享、统一历史**，或每个智能体维护自己的独立历史记录的**分离、独立历史**。这两种模式之间的选择取决于任务的性质和智能体之间期望的协作风格。

对于**共享、统一历史模型**，系统中的所有智能体都从同一个对话历史中读取和写入所有事件。每个智能体的消息、工具调用和观察结果都按时间顺序附加到一个中央日志中。这种方法最适合需要单一事实来源的紧密耦合、协作任务，例如一个智能体的输出是下一个智能体直接输入的多步问题解决过程。即使有共享历史，子智能体在传递给LLM之前可能会处理日志。例如，它可以过滤相关事件的子集或添加标签以识别哪个智能体生成了每个事件。

如果您使用ADK的LLM驱动委派来移交到子智能体，子智能体的所有中间事件将写入与根智能体相同的会话中。

在**分离、独立历史模型**中，每个智能体维护自己的私人对话历史，对其他智能体而言就像一个黑盒。所有内部过程——如中间想法、工具使用和推理步骤——都保留在智能体的私人日志中，其他智能体不可见。通信仅通过显式消息进行，智能体在其中共享其最终输出，而不是其过程。

这种交互通常通过实现**智能体即工具（Agent-as-a-tool）**或使用**智能体到智能体（A2A）协议**来实现。使用智能体即工具，一个智能体调用另一个智能体，就像它是标准工具一样，传递输入并接收最终的、独立的输出。使用A2A协议，智能体使用结构化协议进行直接消息传递。

我们将在下一会话中更详细地探讨A2A协议。

### 3.3 跨多个智能体框架的互操作性

**图4. 使用不同框架的多个智能体之间的A2A通信**

框架对内部数据表示的使用为多智能体系统引入了一个关键的架构权衡：这种将智能体与LLM解耦的抽象，同时也将其与使用其他智能体框架的智能体隔离开来。这种隔离在持久化层得到了巩固。会话的存储模型通常将数据库架构直接与框架的内部对象耦合，创建一个刚性的、相对不可移植的对话记录。因此，使用LangGraph构建的智能体无法原生解释由基于ADK的智能体持久化的不同Session和Event对象，使得无缝任务交接不可能。

**智能体到智能体（A2A）通信**是协调这些隔离智能体之间协作的一个新兴架构模式。虽然这种模式使智能体能够交换消息，但它未能解决共享丰富、有状态上下文的核心问题。每个智能体的对话历史都编码在其框架的内部架构中。因此，任何包含会话事件的A2A消息都需要一个转换层才能有用。

一个更强大的互操作性架构模式涉及将共享知识抽象为与框架无关的数据层，例如**记忆**。与会话存储不同，会话存储保存原始、特定于框架的对象（如事件和消息），记忆层旨在保存经过处理的、规范化的信息。关键信息（如摘要、提取的实体和事实）从对话中提取，通常存储为字符串或字典。记忆层的数据结构不与任何单一框架的内部数据表示耦合，这使其能够作为通用、公共数据层。这种模式允许异构智能体通过共享公共认知资源来实现真正的协作智能，而无需自定义转换器。

### 3.4 会话的生产环境考量

将智能体移动到生产环境时，其会话管理系统必须从简单的日志发展为强大的、企业级的服务。关键的考量分为三个关键领域：**安全和隐私**、**数据完整性**以及**性能**。托管会话存储（如Agent Engine Sessions）专门设计用于解决这些生产需求。

**安全和隐私**

保护会话中包含的敏感信息是不可协商的要求。**严格隔离**是最关键的安全原则。会话由单个用户拥有，系统必须强制严格隔离，以确保一个用户永远无法访问另一个用户的会话数据（即通过ACL）。对会话存储的每个请求都必须经过身份验证和授权，以验证会话所有者。

处理个人身份信息（PII）的最佳实践是在会话数据写入存储之前对其进行**编辑**。这是一项根本性的安全措施，大大降低了潜在数据泄露的风险和影响范围。通过确保敏感数据永远不会被持久化（使用Model Armor等工具），您简化了遵守GDPR和CCPA等隐私法规的工作，并建立了用户信任。

**数据完整性和生命周期管理**

生产系统需要关于如何随时间存储和维护会话数据的明确规则。会话不应该永远存在。您可以实施**生存时间（TTL）策略**来自动删除不活动的会话，以管理存储成本和减少数据管理开销。这需要一个明确的数据保留政策，定义会话在归档或永久删除之前应保留多长时间。

此外，系统必须保证操作以确定性顺序附加到会话历史。维护事件的正确时间顺序对于对话日志的完整性至关重要。

**性能和可扩展性**

会话数据位于每个用户交互的"热路径"上，使其性能成为主要关注点。读取和写入会话历史必须极快，以确保响应迅速的用户体验。智能体运行时通常是无状态的，因此整个会话历史在每一轮开始时从中央数据库检索，产生网络传输延迟。

为了减轻延迟，减少传输的数据大小至关重要。一个关键的优化是在将数据发送给智能体之前**过滤或压缩会话历史**。例如，您可以删除旧的、不再需要的函数调用输出。以下部分详细介绍了几种用于有效管理长上下文对话的压缩策略。

### 3.5 管理长上下文对话：权衡与优化

在简单的架构中，会话是用户和智能体之间对话的不可变日志。然而，随着对话的扩展，对话的token使用量增加。现代LLM可以处理长上下文，但存在限制，特别是对于延迟敏感的应用：

1. **上下文窗口限制**：每个LLM都有一个最大文本量（上下文窗口）它可以同时处理。如果对话历史超过此限制，API调用将失败。
2. **API成本（$）**：大多数LLM提供商根据发送和接收的token数量收费。较短的历史意味着较少的token和每轮较低的成本。
3. **延迟（速度）**：向模型发送更多文本需要更长的处理时间，导致用户响应时间变慢。压缩使智能体感觉快速且响应迅速。
4. **质量**：随着token数量的增加，由于上下文中的额外噪音和自回归错误，性能可能会下降。

管理长对话可以比作精明的旅行者为长途旅行打包行李箱。行李箱代表智能体有限的上下文窗口，衣服和物品是对话中的信息片段。如果你只是试图把所有东西塞进去，行李箱会变得太重和混乱，使你难以快速找到需要的东西——就像过载的上下文窗口增加处理成本并减慢响应时间一样。另一方面，如果你打包得太少，你就有留下必需物品的风险，比如护照或保暖外套，从而危及整个旅程——就像智能体可能丢失关键上下文，导致不相关或不正确的答案。旅行者和智能体都面临类似的约束：成功关键不在于你能携带多少，而在于只携带你需要的东西。

**压缩策略**压缩长对话历史，将对话缩小以适应模型的上下文窗口，降低API成本和延迟。随着对话变长，每轮发送给模型的历史可能变得太大。压缩策略通过智能地修剪历史，同时试图保留最重要的上下文来解决这个问题。

那么，如何在不丢失有价值信息的情况下从会话中丢弃内容？策略范围从简单的截断到复杂的压缩：

- **保留最后N轮**：这是最简单的策略。智能体只保留对话的最后N轮（"滑动窗口"），丢弃所有更早的内容。
- **基于Token的截断**：在将历史发送给模型之前，智能体从最近的开始向后计算消息中的token。它包含尽可能多的消息而不超过预定义的token限制（例如，4000个token）。所有更旧的内容都被简单地切断。
- **递归摘要**：对话的较旧部分被AI生成的摘要替换。随着对话的增长，智能体定期使用另一个LLM调用来摘要最旧的消息。然后，这个摘要用作历史的压缩形式，通常前缀到更近的、逐字的消息。

鉴于复杂的压缩策略旨在降低成本和延迟，**在后台异步执行昂贵操作（如递归摘要）并持久化结果至关重要**。"在后台"确保客户端不被等待，"持久化"确保昂贵计算不会过度重复。通常，智能体的记忆管理器负责生成和持久化这些递归摘要。智能体还必须记录哪些事件包含在压缩摘要中；这可以防止原始的、更详细的事件被不必要地发送给LLM。

此外，智能体必须决定何时需要压缩。触发机制通常分为几个不同的类别：

- **基于计数的触发器**（即token大小或轮数阈值）：当对话超过某个预定义的阈值时进行压缩。这种方法通常对于管理上下文长度"足够好"。
- **基于时间的触发器**：压缩不是由对话大小触发，而是由缺乏活动触发。如果用户停止交互一段设定的时间（例如，15或30分钟），系统可以在后台运行压缩作业。
- **基于事件的触发器**（即语义/任务完成）：当智能体检测到特定任务、子目标或对话主题已结束时，触发压缩。

**记忆生成**是从冗长且嘈杂的数据源中提取持久化知识的广泛能力。在本节中，我们介绍了一个从对话历史中提取信息的主要示例：会话压缩。压缩将整个对话的逐字记录提炼出来，提取关键事实和摘要，同时丢弃对话填充词。

基于压缩，下一部分将更广泛地探讨记忆生成和管理。我们将讨论创建、存储和检索记忆的各种方式，以构建智能体的长期知识。

---

## 4. 记忆

记忆和会话共享着深刻的共生关系：会话是生成记忆的主要数据源，而记忆是管理会话大小的关键策略。**记忆**是从对话或数据源中提取的有意义信息的快照。它是一种保留了重要上下文的浓缩表示，对未来的交互很有用。通常，记忆跨会话持久化，以提供连续且个性化的体验。

作为专门的、解耦的服务，"记忆管理器"为多智能体互操作性提供了基础。记忆管理器经常使用与框架无关的数据结构，如简单的字符串和字典。这允许在不同框架上构建的智能体连接到单个记忆存储，使任何连接的智能体都可以利用共享知识库的创建。

注意：某些框架也可能将会话或逐字对话称为"短期记忆"。对于本白皮书，记忆被定义为提取的信息，而不是逐轮对话的原始对话。

**存储和检索记忆**对于构建复杂且智能的智能体至关重要。强大的记忆系统通过解锁几个关键能力将基本的聊天机器人转变为真正智能的智能体：

- **个性化**：最常见的用例是记住用户偏好、事实和过去交互，以定制未来的响应。例如，记住用户最喜欢的运动队或他们在飞机上的首选座位，创造更有帮助和个性化的体验。
- **上下文窗口管理**：随着对话变长，完整历史可能超过LLM的上下文窗口。记忆系统可以通过创建摘要或提取关键事实来压缩此历史，保留上下文而不在每轮发送数千个token。这降低了成本和延迟。
- **数据挖掘和洞察**：通过以聚合、保护隐私的方式分析许多用户的存储记忆，您可以从噪音中提取洞察。例如，零售聊天机器人可能会识别许多用户在询问特定产品的退货政策，标记潜在问题。
- **智能体自我改进和适应**：智能体通过创建关于其自身表现的程序性记忆来学习以前的运行——记录哪些策略、工具或推理路径导致了成功的结果。这使智能体能够构建有效解决方案的剧本，使其能够随着时间的推移调整和改进其问题解决能力。

在AI系统中创建、存储和利用记忆是一个协作过程。堆栈中的每个组件——从最终用户到开发者的代码——都扮演着不同的角色。

1. **用户**：为记忆提供原始源数据。在某些系统中，用户可以直接提供记忆（即通过表单）。
2. **智能体（开发者逻辑）**：配置如何决定什么以及何时记住，协调对记忆管理器的调用。在简单架构中，开发者可以实现逻辑，使得记忆总是被检索并总是被触发生成。在更高级的架构中，开发者可以实现记忆即工具，智能体（通过LLM）决定何时应该检索或生成记忆。
3. **智能体框架**（例如，ADK、LangGraph）：为记忆交互提供结构和工具。框架充当管道。它定义了开发者的逻辑如何访问对话历史并与记忆管理器交互，但它本身不管理长期存储。它还定义如何将检索到的记忆塞入上下文窗口。
4. **会话存储**（即Agent Engine Sessions、Spanner、Redis）：存储会话的逐轮对话。原始对话将被摄取到记忆管理器中以生成记忆。
5. **记忆管理器**（例如Agent Engine Memory Bank、Mem0、Zep）：处理记忆的存储、检索和压缩。存储和检索记忆的机制取决于使用的提供商。这是将智能体识别的潜在记忆处理其整个生命周期的专门服务或组件。

   - **提取**：从源数据中提炼关键信息。
   - **巩固**：策划记忆以合并重复实体。
   - **存储**：将记忆持久化到持久化数据库。
   - **检索**：获取相关记忆，为新交互提供上下文。

**图5. 会话、记忆和外部知识之间的信息流**

职责分工确保开发者可以专注于智能体的独特逻辑，而无需构建复杂的底层基础设施用于记忆持久化和管理。重要的是要认识到，记忆管理器是一个主动系统，而不仅仅是被动的向量数据库。虽然它使用相似性搜索进行检索，但其核心价值在于智能地提取、巩固和管理记忆的能力。托管记忆服务（如Agent Engine Memory Bank）处理记忆生成和存储的整个生命周期，让您专注于智能体的核心逻辑。

这种检索能力也是记忆经常被与另一个关键架构模式进行比较的原因：检索增强生成（RAG）。然而，它们构建在不同的架构原则上，RAG处理静态外部数据，而记忆策划动态、用户特定的上下文。它们扮演两个不同且互补的角色：RAG使智能体成为事实专家，而记忆使其成为用户专家。

**表1. RAG引擎和记忆管理器的比较**

|                    | RAG引擎                                                                                  | 记忆管理器                                                                                                                                   |
| ------------------ | ---------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------- |
| **主要目标** | 将外部、事实知识注入上下文                                                               | 创建个性化和有状态的体验。智能体记住事实，适应用户，维护长期上下文                                                                           |
| **数据源**   | 静态、预索引的外部知识库（例如PDF、维基、文档、API）                                     | 用户和智能体之间的对话                                                                                                                       |
| **隔离级别** | 通常共享。知识库通常是一个全局的、只读资源，所有用户都可以访问，以确保一致、事实性的答案 | 高度隔离：记忆几乎总是在每个用户级别隔离，以防止数据泄露                                                                                     |
| **信息类型** | 静态、事实性和权威性。通常包含特定领域的数据、产品细节或技术文档                         | 动态且（通常）用户特定。记忆源自对话，因此存在固有的不确定性                                                                                 |
| **写入模式** | 批处理。通过离线管理操作触发                                                             | 事件驱动处理。以某种节奏触发（即每轮或会话结束时）或记忆即工具（智能体决定生成记忆）                                                         |
| **读取模式** | RAG数据几乎总是"作为工具"检索。当智能体决定用户查询需要外部信息时检索                    | 有两种常见读取模式：`<br>`• 记忆即工具：当用户查询需要关于用户（或其他身份）的额外信息时检索`<br>`• 静态检索：在每轮开始时始终检索记忆 |
| **数据格式** | 自然语言"块"                                                                             | 自然语言片段或结构化档案                                                                                                                     |
| **数据准备** | 分块和索引：源文档被分解为小块，然后转换为嵌入并存储以供快速查找                         | 提取和巩固：从对话中提取关键细节，确保内容不重复或矛盾                                                                                       |

理解这种差异的一个有用方法是将RAG视为智能体的研究图书管理员，将记忆管理器视为其个人助理。

研究图书管理员（RAG）在一个充满百科全书、教科书和官方文件的大型公共图书馆工作。当智能体需要一个既定事实时——比如产品的技术规格或历史日期——它会咨询图书管理员。图书管理员从这个静态、共享和权威的知识库中检索信息，以提供一致、事实性的答案。图书管理员是世界事实的专家，但他们对提问的用户一无所知。

相比之下，个人助理（记忆）跟随智能体，携带一个私人笔记本，记录与特定用户每次交互的细节。这个笔记本是动态的且高度隔离的，包含个人偏好、过去的对话和不断变化的目标。当智能体需要回忆用户最喜欢的运动队或上周项目讨论的上下文时，它会求助于助理。助理的专业知识不在于全球事实，而在于用户本身。

最终，一个真正智能的智能体需要两者。RAG为其提供世界专家知识，而记忆为其提供对正在服务的用户的专家理解。

下一部分通过检查其核心组件来解构记忆的概念：它存储的信息类型、其组织模式、其存储和创建的机制、其范围的战略定义，以及其对多模态与文本数据的处理。

### 4.1 记忆类型

智能体的记忆可以通过信息如何存储以及如何捕获来分类。这些不同类型的记忆共同创造了对用户及其需求的丰富、上下文理解。在所有记忆类型中，规则是记忆是描述性的，不是预测性的。

"记忆"是由记忆管理器返回并由智能体用作上下文的原子上下文。虽然确切的架构可能有所不同，但单个记忆通常包含两个主要组件：**内容**和**元数据**。

**内容**是从源数据（即会话的原始对话）中提取的记忆实质。至关重要的是，内容被设计为与框架无关，使用任何智能体都可以轻松摄取的简单数据结构。内容可以是结构化或非结构化数据。

- **结构化记忆**包括通常存储在通用格式（如字典或JSON）中的信息。其架构通常由开发者定义，而不是特定框架。例如：`{"seat_preference": "Window"}`。
- **非结构化记忆**是捕获更长交互、事件或主题本质的自然语言描述。例如："用户更喜欢靠窗座位"。

**元数据**提供关于记忆的上下文，通常存储为简单字符串。这可以包括记忆的唯一标识符、"所有者"的标识符，以及描述内容或记忆数据来源的标签。

### 4.2 信息类型

除了其基本结构外，记忆可以通过它们所代表的知识的基本类型来分类。这种区别对于理解智能体如何使用记忆至关重要，它将记忆分为两个主要功能类别，源自认知科学：**陈述性记忆**（"知道什么"）和**程序性记忆**（"知道如何"）。

**陈述性记忆**是智能体对事实、数字和事件的知识。它是智能体可以明确陈述或"声明"的所有信息。如果记忆是对"什么"问题的回答，那就是陈述性的。这一类别包括一般世界知识（语义）和特定用户事实（实体/情景记忆）。

**程序性记忆**是智能体对技能和工作流程的知识。它通过隐式地展示如何正确执行任务来指导智能体的行动。如果记忆有助于回答"如何"问题——比如预订旅行的正确工具调用序列——那就是程序性的。

### 4.3 组织模式

一旦记忆被创建，下一个问题是如何组织它。记忆管理器通常采用以下一种或多种模式来组织记忆：**集合**、**结构化用户档案**或"**滚动摘要**"这些模式定义了单个记忆如何相互关联以及如何与用户关联。

**集合模式**为单个用户将内容组织成多个独立的、自然语言的记忆。每个记忆是一个独立的事件、摘要或观察，尽管可能有多个记忆属于单个高级主题。集合允许存储和搜索与特定目标或主题相关的更大、结构较少的信息池。

**结构化用户档案模式**将记忆组织为一组关于用户的核心事实，就像一个不断更新新稳定信息的联系卡。它旨在快速查找关于姓名、偏好和账户细节等基本、事实性信息。

与结构化用户档案不同，"**滚动摘要**"模式将所有信息合并到一个不断演变的记忆中，代表整个用户-智能体关系的自然语言摘要。管理器不是创建新的、独立的记忆，而是不断更新这一个主文档。这种模式经常用于压缩长会话，保留重要信息，同时管理总token数量。

### 4.4 存储架构

此外，存储架构是一个关键决策，决定了智能体可以多快、多智能地检索记忆。架构的选择定义了智能体是否擅长寻找概念上相似的想法、理解结构化关系，或两者兼而有之。

记忆通常存储在**向量数据库**和/或**知识图谱**中。向量数据库帮助找到与查询概念上相似的记忆。知识图谱将记忆存储为实体及其关系的网络。

**向量数据库**是最常见的方法，支持基于语义相似性而非精确关键词的检索。记忆被转换为嵌入向量，数据库找到与用户查询最接近的概念匹配。这擅长检索非结构化、自然语言记忆，其中上下文和含义是关键（即"原子事实"）。

**知识图谱**用于将记忆存储为实体（节点）及其关系（边）的网络。检索涉及遍历此图以找到直接和间接连接，允许智能体推理不同事实如何关联。它非常适合结构化、关系查询和理解数据中的复杂连接（即"知识三元组"）。

您还可以通过使用向量嵌入丰富知识图谱的结构化实体，将两种方法组合成**混合方法**。这使系统能够同时执行关系搜索和语义搜索。这提供了图的结构化推理和向量数据库的细微、概念搜索，提供了两全其美的方案。

### 4.5 创建机制

我们还可以通过记忆的创建方式进行分类，包括如何派生信息。**显性记忆**是当用户给智能体直接命令记住某事时创建的（例如，"记住我的纪念日是10月26日"）。另一方面，**隐性记忆**是当智能体在没有直接命令的情况下从对话中推断和提取信息时创建的（例如，"我的纪念日下周就到了。你能帮我给我的伴侣找个礼物吗？"）

记忆还可以通过记忆提取逻辑是位于智能体框架内部还是外部来区分。**内部记忆**是指直接内置在智能体框架中的记忆管理。它方便入门，但通常缺乏高级功能。内部记忆可以使用外部存储，但生成记忆的机制在智能体内部。

**外部记忆**涉及使用专门用于记忆管理的单独、专门的服务（例如，Agent Engine Memory Bank、Mem0、Zep）。智能体框架对此外部服务进行API调用以存储、检索和处理记忆。这种方法提供了更复杂的功能，如语义搜索、实体提取和自动摘要，将复杂的记忆管理任务卸载到专门构建的工具。

### 4.6 记忆范围

您还需要考虑记忆描述的是谁或什么。这影响您用于聚合和检索记忆的实体（即用户、会话或应用程序）。

**用户级别范围**是最常见的实现，旨在为每个个体创建连续、个性化的体验；例如，"用户更喜欢中间座位"。记忆与特定用户ID关联，并在其所有会话中持久化，允许智能体建立对其偏好和历史的长期理解。

**会话级别范围**旨在压缩长对话；例如，"用户正在2025年11月7日至2025年11月14日之间购买纽约和巴黎之间的机票。他们更喜欢直飞航班和中间座位"。它从单个会话中提取洞察的持久化记录，允许智能体用简洁的关键事实集替换冗长的、token密集的记录。至关重要的是，这种记忆与原始会话日志不同；它只包含从对话中处理的洞察，而不是对话本身，其上下文隔离到该特定会话。

**应用程序级别范围**（或全局上下文）是应用程序所有用户都可以访问的记忆；例如，"代号XYZ指的是项目……"。此范围用于提供共享上下文、广播系统范围的信息或建立基线常识。应用程序级别记忆的常见用例是程序性记忆，它为智能体提供"如何"指令；这些记忆通常旨在帮助所有用户的智能体推理。至关重要的是，这些记忆必须清除所有敏感内容，以防止用户之间的数据泄露。

### 4.7 多模态记忆

"多模态记忆"是一个关键概念，描述了智能体如何处理非文本信息，如图像、视频和音频。关键是区分记忆来源的数据（其来源）和记忆存储的数据（其内容）。

**来自多模态源的记忆**是最常见的实现。智能体可以处理各种数据类型——文本、图像、音频——但它创建的记忆是从该来源派生的文本洞察。例如，智能体可以处理用户的语音备忘录来创建记忆。它不存储音频文件本身；相反，它转录音频并创建文本记忆，如"用户对最近的运输延误表示沮丧"。

**具有多模态内容的记忆**是一种更高级的方法，其中记忆本身包含非文本媒体。智能体不只是描述内容；它直接存储内容。例如，用户可以上传图像并说"记住这个作为我们的标志设计"。智能体创建一个直接包含图像文件的记忆，链接到用户的请求。

大多数当代记忆管理器专注于处理多模态源，同时产生文本内容。这是因为为特定记忆生成和检索非结构化二进制数据（如图像或音频）需要专门的模型、算法和基础设施。将所有输入转换为通用的、可搜索的格式要简单得多：文本。

### 4.8 记忆生成：提取与巩固

记忆生成自主地将原始对话数据转换为结构化、有意义的洞察，发挥作用。将其视为一个LLM驱动的ETL（提取、转换、加载）管道，旨在提取和浓缩记忆。记忆生成的ETL管道将记忆管理器与RAG引擎和传统数据库区分开来。记忆管理器不是要求开发者手动指定数据库操作，而是使用LLM来智能地决定何时添加、更新或合并记忆。这种自动化是记忆管理器的核心优势；它抽象了管理数据库内容、链接LLM调用和部署数据处理后台服务的复杂性。

**图6. 记忆生成的高级算法，从数据源提取记忆并与现有记忆巩固**

虽然具体算法因平台而异（例如，Agent Engine Memory Bank、Mem0、Zep），但记忆生成的高级过程通常遵循以下四个阶段：

1. **摄取**：当客户端向记忆管理器提供原始数据源（通常是对话历史）时，过程开始。
2. **提取与过滤**：记忆管理器使用LLM从源数据中提取有意义的内容。关键是这个LLM不会提取所有内容；它只捕获符合预定义主题定义的信息。如果摄取的数据不包含与这些主题匹配的信息，则不会创建记忆。
3. **巩固**：这是最复杂的阶段，记忆管理器处理冲突解决和去重。它执行"自我编辑"过程，使用LLM将新提取的信息与现有记忆进行比较。为了确保用户的知识库保持连贯、准确，并基于新信息随时间演变，管理器可以决定：

   - 将新洞察合并到现有记忆中。
   - 如果现有记忆现在无效，则删除它。
   - 如果主题是新颖的，则创建一个全新的记忆。
4. **存储**：最后，新的或更新的记忆被持久化到持久化存储层（如向量数据库或知识图谱），以便在未来的交互中可以检索。

托管记忆管理器（如Agent Engine Memory Bank）完全自动化此管道。它们提供了一个单一的、连贯的系统，将对话噪音转化为结构化知识，让开发者专注于智能体逻辑，而不是自己构建和维护底层数据基础设施。

现在，让我们深入探讨记忆生成的两个关键步骤：提取和巩固。

### 4.9 记忆溯源

经典的机器学习公理"垃圾进，垃圾出"对LLM更为关键，其结果往往是"垃圾进，自信的垃圾出"。为了让智能体做出可靠的决策，记忆管理器有效地巩固记忆，它们必须能够批判性地评估自身记忆的质量。这种可信度直接来源于记忆的**溯源**——其起源和历史的详细记录。

**图7. 数据源和记忆之间的信息流。单个记忆可以从多个数据源派生，单个数据源可能贡献给多个记忆。**

记忆巩固的过程——将来自多个来源的信息合并为单个、不断演变的记忆——产生了追踪其谱系的需求。如上图所示，单个记忆可能是多个数据源的混合，单个源可能被分割成多个记忆。

为了评估可信度，智能体必须追踪每个来源的关键细节，如其来源（源类型）和年龄（"新鲜度"）。这些细节至关重要，有两个原因：它们决定了每个来源在记忆巩固期间的权重，它们告知智能体在推理期间应该多大程度上依赖该记忆。

**源类型**是确定信任度的最重要因素之一。数据源分为三个主要类别：

- **引导数据**：从内部系统（如CRM）预加载的信息。这种高信任度数据可用于初始化用户记忆，以解决冷启动问题——即向智能体从未交互过的用户提供个性化体验的挑战。
- **用户输入**：这包括明确提供的数据（例如，通过表单，这是高信任的）或从对话中隐式提取的信息（通常不太可信）。
- **工具输出**：从外部工具调用返回的数据。从工具输出生成记忆通常是不鼓励的，因为这些记忆往往脆弱且过时，使这种源类型更适合短期缓存。

在记忆管理期间考虑记忆谱系

这种动态、多源的记忆方法在管理记忆时产生了两个主要操作挑战：**冲突解决**和**删除派生数据**。

记忆巩固不可避免地导致冲突，其中一个数据源与另一个数据源冲突。记忆的溯源允许记忆管理器为其信息源建立信任层次。当来自不同来源的记忆相互矛盾时，智能体必须在冲突解决策略中使用此层次。常见策略包括优先考虑最可信的来源、支持最新信息或寻找多个数据点之间的佐证。

管理记忆的另一个挑战发生在删除记忆时。记忆可以从多个数据源派生。当用户撤销对一个数据源的访问时，源自该源的数据也应被删除。删除该源"触及"的每个记忆可能过于激进。一种更精确但计算成本高的方法是仅使用剩余的、有效的源从头开始重新生成受影响的记忆。

除了静态溯源细节外，对记忆的**信心**必须演变。信心通过**佐证**增加，例如当多个可信来源提供一致信息时。然而，高效的记忆系统还必须通过**记忆修剪**主动策划其现有知识——识别并"遗忘"不再有用的记忆的过程。这种修剪可以由几个因素触发：

- **基于时间的衰减**：记忆的重要性可能随时间减少。关于两年前会议的记忆可能比上周的记忆相关性更低。
- **低信心**：由弱推断创建且从未被其他来源佐证的记忆可能被修剪。
- **不相关性**：随着智能体对用户的理解更加复杂，它可能确定一些较旧的、琐碎的记忆与用户当前目标不再相关。

通过将反应性巩固管道与主动修剪相结合，记忆管理器确保智能体的知识库不是曾经说过的所有内容的增长日志。相反，它是一个策划的、准确的、相关的用户理解。

在推理期间考虑记忆谱系

除了在策划语料库内容时考虑记忆的谱系外，在推理时也应考虑记忆的可信度。智能体对记忆的信心不应该是静态的；它必须基于新信息和时间推移而演变。信心通过佐证增加，例如当多个可信来源提供一致信息时。相反，信心随时间衰减（随着记忆变旧），并在引入矛盾信息时下降。最终，系统可以通过归档或删除低信心记忆来"遗忘"。这种动态信心分数在推理时至关重要。

与其向用户展示，不如将记忆及其信心分数（如果可用）注入到提示中，使LLM能够评估信息的可靠性并做出更细致的决策。

这个整个信任框架服务于智能体的内部推理过程。记忆及其信心分数通常不直接向用户展示。相反，它们被注入到系统提示中，允许LLM权衡证据，考虑其信息的可靠性，并最终做出更细致和可信的决策。

### 4.10 触发记忆生成

虽然记忆管理器一旦触发生成就自动化记忆提取和巩固，但智能体仍必须决定何时应尝试生成记忆。这是一个关键的架构选择，平衡数据新鲜度与计算成本和延迟。这个决定通常由智能体的逻辑管理，它可以采用多种触发策略。记忆生成可以基于各种事件启动：

- **会话完成**：在多轮会话结束时触发生成。
- **轮次节奏**：在特定轮数后运行该过程（例如，每5轮）。
- **实时**：在每一轮之后生成记忆。
- **显式命令**：在直接用户命令时激活该过程（例如，"记住这个"）。

触发器的选择涉及成本和保真度之间的直接权衡。频繁生成（例如，实时）确保记忆高度详细和新鲜，捕捉对话的每一个细微差别。然而，这会产生最高的LLM和数据库成本，如果处理不当可能会引入延迟。不频繁生成（例如，在会话完成时）成本效益高得多，但可能导致保真度较低的记忆，因为LLM必须一次摘要更大的对话块。您还需要小心记忆管理器不要多次处理相同的事件，因为这会引入不必要的成本。

### 4.11 记忆作为工具

一种更复杂的方法是允许智能体自己决定何时创建记忆。在这种模式中，记忆生成被公开为工具（即 `create_memory`）；工具定义应定义什么类型的信息应被视为有意义。然后，智能体可以分析对话并自主决定调用此工具，当它识别出值得持久化的信息时。这将在外部记忆管理器中识别"有意义信息"的责任转移到智能体（因此您作为开发者）。

例如，您可以使用ADK通过将记忆生成代码打包成智能体决定调用的工具（当它认为对话值得持久化时）来实现这一点。您可以将会话发送到Memory Bank，Memory Bank将从对话历史中提取和巩固记忆。

另一种方法是利用内部记忆，智能体主动决定从对话中记住什么。在这个工作流程中，智能体负责提取关键信息。然后，可选地，将这些提取的记忆发送到Agent Engine Memory Bank，与用户的现有记忆巩固。

### 4.12 后台与阻塞操作

记忆生成是一项需要LLM调用和数据库写入的昂贵操作。对于生产中的智能体，记忆生成**几乎总应作为后台进程异步处理**。

在智能体向用户发送响应后，记忆生成管道可以并行运行，而不会阻塞用户体验。这种解耦对于保持智能体感觉快速且响应迅速至关重要。**阻塞**（或同步）方法，即用户必须等待记忆写入才能收到响应，会创造不可接受的缓慢和令人沮丧的用户体验。这要求记忆生成在与智能体核心运行时架构上分离的服务中发生。

### 4.13 记忆检索

有了记忆生成的机制，您的焦点可以转移到关键的检索任务。智能检索策略对于智能体的性能至关重要，涵盖了应该检索哪些记忆以及何时检索的决策。

检索记忆的策略很大程度上取决于记忆的组织方式。对于结构化用户档案，检索通常是对完整档案或特定属性的直接查找。然而，对于记忆集合，检索是一个更复杂的搜索问题。目标是从大量非结构化或半结构化数据池中发现最相关、概念上相关的信息。本节讨论的策略旨在解决记忆集合的这一复杂检索挑战。

记忆检索搜索与当前对话最相关的记忆。有效的检索策略至关重要；提供不相关的记忆可能会混淆模型并降低其响应，而找到完美的上下文片段可以带来显著智能的交互。核心挑战是在严格的延迟预算内平衡记忆的"有用性"。

先进的记忆系统超越了简单搜索，跨多个维度对潜在记忆进行评分，以找到最佳匹配。

- **相关性（语义相似性）**：此记忆与当前对话的概念相关程度？
- **新近性（基于时间）**：此记忆是何时创建的？
- **重要性（重要性）**：此记忆整体有多重要？与相关性不同，记忆的"重要性"可能在生成时定义。

仅依赖基于向量的相关性是一个常见的陷阱。相似性分数可能产生概念上相似但陈旧或琐碎的记忆。最有效的策略是结合所有三个维度分数的**混合方法**。

对于准确性至关重要的应用，可以使用**查询重写**、**重排序**或**专门检索器**等方法来细化检索。然而，这些技术在计算上很昂贵，并增加显著的延迟，使它们不适合大多数实时应用。对于这些复杂算法必要且记忆不会快速变陈的场景，**缓存层**可以是一种有效的缓解措施。缓存允许临时存储检索查询的昂贵结果，绕过后续相同请求的高延迟成本。

使用**查询重写**，LLM可以用来改进搜索查询本身。这可能涉及将用户的模糊输入重写为更精确的查询，或将单个查询扩展为多个相关查询以捕获主题的不同方面。虽然这显著改善了初始搜索结果的质量，但它在过程开始时增加了一个额外LLM调用的延迟。

使用**重排序**，初始检索使用相似性搜索获取一小组候选记忆（例如，前50个结果）。然后，LLM可以重新评估并重新排序这个较小的集合，以产生更准确的最终列表。

最后，您可以使用微调来训练**专门检索器**。然而，这需要访问标记数据，并可能显著增加成本。

最终，检索的最佳方法始于更好的记忆生成。确保记忆语料库高质量且不包含无关信息是确保任何一组检索记忆都会有帮助的最有效方法。

**检索时机**

检索的最后一个架构决定是何时检索记忆。一种方法是**主动检索**，即在每轮开始时自动加载记忆。这确保上下文始终可用，但为不需要记忆访问的轮次引入不必要的延迟。由于记忆在单轮中保持静态，它们可以被有效地缓存以减轻这种性能成本。

另一种方法是**反应性检索**（"记忆即工具"），其中智能体被赋予查询其记忆的工具，自行决定何时检索上下文。这更高效、更稳健，但需要额外的LLM调用，增加延迟和成本；然而，只有在必要时才检索记忆，因此延迟成本不会频繁产生。此外，智能体可能不知道是否存在相关信息可供检索。然而，这可以通过让智能体了解可用记忆类型（例如，在工具描述中，如果您使用自定义工具）来缓解，从而更明智地决定何时查询。

### 4.14 推理中的记忆

一旦检索到相关记忆，最后一步是将它们战略性地放置到模型的上下文窗口中。这是一个关键过程；记忆的放置可以显著影响LLM的推理，影响运营成本，并最终决定最终答案的质量。

记忆主要通过附加到系统指令或注入到对话历史来呈现。实际上，混合策略通常最有效。对稳定的、全局的记忆（如用户档案）使用系统提示，这些记忆应始终存在。否则，对短暂的、情景的记忆使用对话注入或记忆即工具，这些记忆仅与对话的即时上下文相关。这平衡了持久上下文的需求与即时信息检索的灵活性。

**系统指令中的记忆**

使用记忆进行推理的一个简单选项是将记忆附加到系统指令。此方法通过将检索到的记忆直接附加到系统提示（附带前言）来保持对话历史干净，将它们构建为整个交互的基础上下文。例如，您可以使用Jinja将记忆动态添加到系统指令。

将记忆包含在系统指令中赋予记忆高权威性，将上下文与对话干净地分离，非常适合稳定的、"全局"信息，如用户档案。然而，存在过度影响的风险，智能体可能会试图将每个话题与其核心指令中的记忆联系起来，即使不合适。

这种架构模式引入了几个约束。首先，它要求智能体框架在每次LLM调用之前支持系统提示的动态构建；这种功能并不总是易于支持。此外，该模式与"记忆即工具"不兼容，因为系统提示必须在LLM决定调用记忆检索工具之前最终确定。最后，它处理非文本记忆的能力较差。大多数LLM只接受文本作为系统指令，使得将图像或音频等多模态内容直接嵌入到提示中具有挑战性。

**对话历史中的记忆**

在这种方法中，检索到的记忆被直接注入到逐轮对话中。记忆可以放置在完整对话历史之前，或放置在最新用户查询之前。

然而，这种方法可能很嘈杂，增加token成本，如果检索到的记忆不相关，可能会混淆模型。其主要风险是**对话注入**，其中模型可能错误地将记忆视为对话中实际说过的话。您还需要更小心地注意注入对话的记忆的视角；例如，如果您使用"用户"角色和用户级记忆，记忆应以第一人称书写。

将记忆作为工具调用注入对话历史是一个特殊情况。记忆将作为工具输出的一部分直接包含在对话中。

### 4.15 程序性记忆

本白皮书主要关注陈述性记忆，这种关注反映了当前商业记忆领域。大多数记忆管理平台也为这种陈述性方法而架构，擅长提取、存储和检索"什么"——事实、历史和用户数据。

然而，这些系统并非设计来管理**程序性记忆**，即改进智能体工作流程和推理的机制。存储"如何"不是一个信息检索问题；它是一个推理增强问题。管理这种"知道如何"需要一个完全独立和专门的算法生命周期，尽管具有类似的高级结构：

1. **提取**：程序性提取需要专门的提示，旨在从成功的交互中提炼可重用的策略或"剧本"，而不仅仅是捕获事实或有意义的信息。
2. **巩固**：虽然陈述性巩固合并相关事实（"什么"），但程序性巩固策划工作流程本身（"如何"）。这是一个活跃的逻辑管理过程，专注于将新方法与现有"最佳实践"整合，修补已知计划中的有缺陷步骤，以及修剪过时或无效的程序。
3. **检索**：目标不是检索数据来回答问题，而是检索指导智能体如何执行复杂任务的计划。因此，程序性记忆可能具有与陈述性记忆不同的数据架构。

智能体"自我演进"其逻辑的能力自然会与常见的适应方法进行比较：**微调**——通常通过来自人类反馈的强化学习（RLHF）。虽然这两个过程都旨在改进智能体行为，但它们的机制和应用是根本不同的。微调是一个相对缓慢、离线训练过程，改变模型权重。程序性记忆通过动态地将正确的"剧本"注入提示，提供快速、在线的适应，通过上下文学习指导智能体，而无需任何微调。

---

## 5. 测试与评估

现在您已经有了支持记忆的智能体，您应该通过全面的质量和评估测试来验证其性能。评估智能体的记忆是一个多层次的过程。评估需要验证智能体记住的是正确的事情（**质量**），它可以在需要时找到这些记忆（**检索**），以及使用这些记忆实际上有助于它完成目标（**任务成功**）。虽然学术界关注可复现的基准，但行业评估集中在记忆如何直接影响生产智能体的性能和可用性。

**记忆生成质量指标**评估记忆本身的内容，回答这个问题："智能体记住的是正确的事情吗？"这通常通过将智能体生成的记忆与手动创建的"黄金标准"理想记忆进行比较来衡量。

- **精确度**：智能体创建的所有记忆中，有多少百分比是准确且相关的？高精确度防止"过于急切"的记忆系统用无关噪音污染知识库。
- **召回率**：从源中应该记住的所有相关事实中，它捕获了多少百分比？高召回率确保智能体不会错过关键信息。
- **F1分数**：精确度和召回率的调和平均值，提供单一、平衡的质量衡量标准。

**记忆检索性能指标**评估智能体在正确时间找到正确记忆的能力。

- **Recall@K**：当需要记忆时，正确的是否在前'K'个检索结果中找到？这是检索系统准确性的主要衡量标准。
- **延迟**：检索位于智能体响应的"热路径"上。整个检索过程必须在严格的延迟预算内执行（例如，200毫秒以下），以避免降低用户体验。

**端到端任务成功指标**是最终的测试，回答这个问题："记忆实际上有助于智能体更好地完成工作吗？"这是通过评估智能体在使用其记忆时下游任务的表现来衡量的，通常使用LLM"评判员"将智能体的最终输出与黄金答案进行比较。评判员确定智能体的答案是否准确，有效衡量记忆系统对最终结果的贡献程度。

评估不是一次性事件；它是一个持续改进的引擎。上述指标提供了识别弱点和随时间系统增强记忆系统所需的数据。这个迭代过程涉及建立基线、分析失败、调优系统（例如，优化提示、调整检索算法）以及重新评估以衡量更改的影响。

虽然上述指标侧重于质量，但生产就绪性还取决于性能。对于每个评估领域，测量底层算法的延迟及其在负载下扩展的能力至关重要。在"热路径"上检索记忆可能有严格的亚秒级延迟预算。生成和巩固虽然通常是异步的，但必须有足够的吞吐量以跟上用户需求。最终，成功的记忆系统必须在现实世界中智能、高效且稳健。

---

## 6. 记忆的生产环境考量

除了性能之外，将支持记忆的智能体从原型过渡到生产需要关注企业级的架构问题。此举引入了可扩展性、弹性和安全性的关键要求。生产级系统必须不仅为智能而设计，还要为企业级的稳健性而设计。

为了确保用户体验永远不会被计算昂贵的记忆生成过程阻塞，强大的架构必须将记忆处理与主应用程序逻辑**解耦**。虽然这是一个事件驱动的模式，但它通常通过对专用记忆服务的直接、非阻塞API调用来实现，而不是自管理的消息队列。流程如下：

1. **智能体推送数据**：在相关事件（例如，会话结束）后，智能体应用对记忆管理器进行非阻塞API调用，"推送"原始源数据（如对话记录）进行处理。
2. **记忆管理器在后台处理**：记忆管理服务立即确认请求，并将生成任务放入其自己的内部托管队列。然后，它完全负责异步的繁重工作：进行必要的LLM调用以提取、巩固和格式化记忆。管理器可能会延迟处理事件，直到经过一定的闲置期。
3. **记忆被持久化**：服务将最终记忆——可能是新条目或对现有条目的更新——写入专用的、持久的数据库。对于托管记忆管理器，存储是内置的。
4. **智能体检索记忆**：然后，主智能体应用可以在需要为新用户交互检索上下文时直接查询此记忆存储。

这种基于服务的、非阻塞的方法确保记忆管道中的失败或延迟不会直接影响面向用户的应用，使系统更具弹性。它还告知了在线（实时）生成和离线（批处理）处理之间的选择，前者非常适合对话新鲜度，后者对于从历史数据填充系统很有用。

随着应用的增长，记忆系统必须处理高频率事件而不会失败。鉴于并发请求，系统必须防止多个事件尝试修改相同记忆时发生死锁或竞争条件。您可以使用**事务数据库操作**或**乐观锁**来缓解竞争条件；然而，当多个请求尝试修改相同记忆时，这可能会引入排队或限制。强大的**消息队列**对于缓冲大量事件并防止记忆生成服务不堪重负至关重要。

记忆服务还必须对瞬时错误具有弹性（**故障处理**）。如果LLM调用失败，系统应使用**指数退避重试机制**，并将持续失败路由到**死信队列**进行分析。

对于全球应用，记忆管理器必须使用具有内置**多区域复制**的数据库，以确保低延迟和高可用性。客户端复制是不可行的，因为巩固需要单一、事务一致的数据视图以防止冲突。因此，记忆系统必须内部处理复制，向开发者呈现单一的逻辑数据存储，同时确保底层知识库全局一致。

托管记忆系统（如Agent Engine Memory Bank）应该帮助您解决这些生产考量，以便您可以专注于核心智能体逻辑。

---

## 7. 隐私与安全风险

记忆源自并包含用户数据，因此它们需要严格的隐私和安全控制。一个有用的类比是将系统记忆视为由**专业档案管理员**管理的**安全企业档案**，其工作是保存有价值的知识，同时保护公司。

此档案的基本规则是**数据隔离**。就像档案管理员永远不会混合来自不同部门的机密文件一样，记忆必须在用户或租户级别严格隔离。为一个用户服务的智能体绝不能访问另一个用户的记忆，使用限制性访问控制列表（ACL）强制执行。此外，用户必须对其数据具有程序化控制，具有明确的选项以选择退出记忆生成或请求从档案中删除其所有文件。

在归档任何文档之前，档案管理员执行关键的安全步骤。首先，他们仔细审查每一页以**编辑敏感个人信息（PII）**，确保知识被保存而不会产生责任。其次，档案管理员受过培训，能够识别和丢弃伪造或故意误导的文件——**记忆投毒**的保障措施。同样，系统必须在将信息提交到长期记忆之前验证和消毒信息，以防止恶意用户通过提示注入破坏智能体的持久知识。系统必须包括Model Armor等保障措施，在将信息提交到长期记忆之前验证和消毒信息。

此外，如果多个用户共享同一组记忆，如**程序性记忆**（教智能体如何做某事），则存在**数据泄露**风险。例如，如果一个用户的程序性记忆被用作另一个用户的示例——比如在公司范围内分享备忘录——档案管理员必须首先执行严格的匿名化，以防止敏感信息跨用户边界泄露。

---

## 8. 结论

本白皮书探讨了上下文工程的学科，重点介绍其两个核心组件：会话和记忆。从简单的对话轮次到持久、可操作智能的旅程由这一实践支配，它涉及动态组装所有必要信息——包括对话历史、记忆和外部知识——到LLM的上下文窗口中。整个过程依赖于两个不同但相互关联的系统之间的相互作用：即时的会话和长期的记忆。

**会话**管理"现在"，充当单次对话的低延迟、时间顺序容器。其主要挑战是性能和安全性，需要低延迟访问和严格隔离。为了防止上下文窗口溢出和延迟，您必须使用提取技术，如基于token的截断或递归摘要，来压缩会话历史或单个请求有效载荷中的内容。此外，安全至关重要，要求在持久化会话数据之前进行PII编辑。

**记忆**是长期个性化的引擎，是跨多个会话持久化的核心机制。它超越了RAG（使智能体成为事实专家），使智能体成为用户专家。记忆是一个主动的、LLM驱动的ETL管道——负责提取、巩固和检索——从对话历史中提炼最重要的信息。通过提取，系统最关键的信息被提炼成关键记忆点。在此之后，巩固策划并将这些新信息与现有语料库整合，解决冲突并删除冗余数据，以确保连贯的知识库。为了保持响应迅速的用户体验，记忆生成必须在智能体响应后作为异步后台进程运行。通过追踪溯源并采用针对记忆投毒等风险的保障措施，开发者可以构建真正与用户一起学习和成长的可信、自适应助手。

---

## 9. 尾注

1. https://cloud.google.com/use-cases/retrieval-augmented-generation?hl=en
2. https://arxiv.org/abs/2301.00234
3. https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/sessions/overview
4. https://langchain-ai.github.io/langgraph/concepts/multi_agent/#message-passing-between-agents
5. https://google.github.io/adk-docs/agents/multi-agents/
6. https://google.github.io/adk-docs/agents/multi-agents/#c-explicit-invocation-agenttool
7. https://agent2agent.info/docs/concepts/message/
8. https://developers.googleblog.com/en/a2a-a-new-era-of-agent-interoperability/
9. https://cloud.google.com/security-command-center/docs/model-armor-overview
10. https://ai.google.dev/gemini-api/docs/long-context#long-context-limitations
11. https://huggingface.co/blog/Kseniase/memory
12. https://langchain-ai.github.io/langgraph/concepts/memory/#semantic-memory
13. https://langchain-ai.github.io/langgraph/concepts/memory/#semantic-memory
14. https://arxiv.org/pdf/2412.15266
15. https://arxiv.org/pdf/2412.15266
16. https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#sample-requests-text-gen-multimodal-prompt
17. https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/memory-bank/generate-memories
18. https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/control-generated-output
19. https://cloud.google.com/agent-builder/agent-engine/memory-bank/set-up#memory-bank-config
20. https://arxiv.org/html/2504.19413v1
21. https://google.github.io/adk-docs/tools/#how-agents-use-tools
22. https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/memory-bank/generate-memories#consolidate-pre-extracted-memories
23. https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/memory-bank/generate-memories#background-memory-generation
24. https://arxiv.org/pdf/2503.08026
25. https://google.github.io/adk-docs/callbacks/
26. https://arxiv.org/html/2508.06433v2
27. https://cloud.google.com/blog/products/ai-machine-learning/rlhf-on-google-cloud
28. https://arxiv.org/pdf/2503.03704
29. https://cloud.google.com/security-command-center/docs/model-armor-overview
30. https://cloud.google.com/architecture/choose-design-pattern-agentic-ai-system

---

**翻译完成**
